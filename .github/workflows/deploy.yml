name: Deploy

on:
  push:
    branches: [main]

concurrency:
  group: deploy-prod
  cancel-in-progress: false

permissions:
  contents: read
  actions: read
  pull-requests: read

env:
  NODE_VERSION: '20'
  TURBO_TOKEN: ${{ secrets.TURBO_TOKEN }}
  TURBO_TEAM: ${{ vars.TURBO_TEAM }}
  AWS_REGION: ${{ vars.AWS_REGION || 'us-east-1' }}
  # Bootstrap image: pulled and pushed to private ECR on first deploy so Lambda has a valid
  # image URI at creation time. This is the single source of truth for the base image digest.
  # The Terraform placeholder_image_uri variable default mirrors this value for local runs only;
  # CI always overrides it via -var. To refresh the digest: bash scripts/get-lambda-bootstrap-digest.sh
  LAMBDA_BOOTSTRAP_IMAGE: 'public.ecr.aws/lambda/nodejs@sha256:b1d950b97aaedc054c6c9c5409c98cf5c8f29de370a6f344113e1aeeaa441707'

jobs:
  build:
    name: Build
    runs-on: ubuntu-latest

    steps:
      - name: Checkout
        uses: actions/checkout@v6

      - name: Setup Node.js
        uses: actions/setup-node@v6
        with:
          node-version-file: '.nvmrc'
          cache: 'npm'

      - name: Install dependencies
        run: npm ci

      - name: Build
        run: npm run build

      - name: Type Check
        run: npm run typecheck

      - name: Lint
        run: npm run lint

      - name: Test
        run: npm run test

      - name: Upload API artifact
        uses: actions/upload-artifact@v6
        with:
          name: api-dist
          path: apps/api/dist/
          retention-days: 1

      - name: Upload migrate artifact
        uses: actions/upload-artifact@v6
        with:
          name: migrate-dist
          path: tools/migrate/dist/
          retention-days: 1

      - name: Upload image-processor artifact
        uses: actions/upload-artifact@v6
        with:
          name: image-processor-dist
          path: apps/image-processor/dist/
          retention-days: 1

  terraform:
    name: Terraform Apply (prod)
    runs-on: ubuntu-latest
    needs: build
    environment: prod

    outputs:
      lambda_function_name: ${{ steps.output.outputs.lambda_function_name }}
      migrate_function_name: ${{ steps.output.outputs.migrate_function_name }}
      image_processor_function_name: ${{ steps.output.outputs.image_processor_function_name }}
      api_gateway_url: ${{ steps.output.outputs.api_gateway_url }}
      ecr_repository_url: ${{ steps.output.outputs.ecr_repository_url }}
      migrate_ecr_repository_url: ${{ steps.output.outputs.migrate_ecr_repository_url }}
      image_processor_ecr_repository_url: ${{ steps.output.outputs.image_processor_ecr_repository_url }}

    steps:
      - name: Checkout
        uses: actions/checkout@v6

      - name: Setup Terraform
        uses: hashicorp/setup-terraform@v3
        with:
          terraform_version: '1.5'
          terraform_wrapper: false

      - name: Configure AWS Credentials
        uses: aws-actions/configure-aws-credentials@v6
        with:
          aws-access-key-id: ${{ secrets.AWS_ACCESS_KEY_ID }}
          aws-secret-access-key: ${{ secrets.AWS_SECRET_ACCESS_KEY }}
          aws-region: ${{ env.AWS_REGION }}

      - name: Terraform Init
        working-directory: infrastructure/terraform
        run: |
          terraform init \
            -backend-config="key=prod/terraform.tfstate"

      # Bootstrap: create ECR repos before Lambdas so we can push images.
      # Lambda (package_type=Image) requires a private ECR image; public ECR URIs are invalid.
      - name: Bootstrap ECR Repositories
        working-directory: infrastructure/terraform
        run: |
          terraform apply -auto-approve -input=false \
            -target=aws_ecr_repository.api \
            -target=aws_ecr_lifecycle_policy.api \
            -target=aws_ecr_repository_policy.api \
            -target=aws_ecr_repository.migrate \
            -target=aws_ecr_lifecycle_policy.migrate \
            -target=aws_ecr_repository_policy.migrate \
            -target=aws_ecr_repository.image_processor \
            -target=aws_ecr_lifecycle_policy.image_processor \
            -target=aws_ecr_repository_policy.image_processor \
            -var-file="environments/prod.tfvars" \
            -var="db_password=${{ secrets.TF_VAR_db_password }}" \
            -var="google_client_id=${{ secrets.TF_VAR_google_client_id }}" \
            -var="google_client_secret=${{ secrets.TF_VAR_google_client_secret }}" \
            -var="alert_email_address=${{ secrets.TF_VAR_alert_email_address }}" \
            -var="placeholder_image_uri=${{ env.LAMBDA_BOOTSTRAP_IMAGE }}"

      - name: Login to Amazon ECR (bootstrap)
        uses: aws-actions/amazon-ecr-login@v2

      # Push bootstrap image to any empty ECR repos on first deploy.
      # Subsequent deploys already have valid images from previous deploy-lambdas runs.
      - name: Push bootstrap image to ECR repos if empty
        id: bootstrap
        working-directory: infrastructure/terraform
        run: |
          API_ECR_URL=$(terraform output -raw ecr_repository_url)
          MIGRATE_ECR_URL=$(terraform output -raw migrate_ecr_repository_url)
          IMAGE_PROCESSOR_ECR_URL=$(terraform output -raw image_processor_ecr_repository_url)

          push_bootstrap_if_empty() {
            local ecr_url="$1"
            local label="$2"
            local ecr_repo="${ecr_url##*/}"
            local image_count

            image_count=$(aws ecr describe-images \
              --repository-name "$ecr_repo" \
              --query 'length(imageDetails)' \
              --output text 2>/dev/null || echo "0")

            if [ "$image_count" = "0" ]; then
              echo "$label ECR is empty ‚Äî pushing bootstrap image..."
              docker tag "$LAMBDA_BOOTSTRAP_IMAGE" "$ecr_url:bootstrap"
              docker push "$ecr_url:bootstrap"
            fi
          }

          # Pull bootstrap image once, push to any empty ECR repos
          docker pull "$LAMBDA_BOOTSTRAP_IMAGE"
          push_bootstrap_if_empty "$API_ECR_URL" "API"
          push_bootstrap_if_empty "$MIGRATE_ECR_URL" "Migrate"
          push_bootstrap_if_empty "$IMAGE_PROCESSOR_ECR_URL" "Image Processor"

          # Determine placeholder URI for Terraform (API ECR as source of truth).
          # Both Lambda modules share this same placeholder_image_uri on initial
          # creation only. After first deploy, lifecycle { ignore_changes = [image_uri] }
          # takes over and CI manages each Lambda's image independently.
          API_ECR_REPO="${API_ECR_URL##*/}"
          if aws ecr describe-images \
              --repository-name "$API_ECR_REPO" \
              --image-ids imageTag=bootstrap &>/dev/null; then
            echo "API ECR has :bootstrap ‚Äî using as placeholder"
            echo "placeholder_uri=$API_ECR_URL:bootstrap" >> "$GITHUB_OUTPUT"
          else
            # No :bootstrap exists (repo has only SHA tags from previous deploys).
            # Push :bootstrap so the placeholder URI points to a real image.
            echo "No :bootstrap ‚Äî pushing :bootstrap now"
            docker tag "$LAMBDA_BOOTSTRAP_IMAGE" "$API_ECR_URL:bootstrap"
            docker push "$API_ECR_URL:bootstrap"
            echo "placeholder_uri=$API_ECR_URL:bootstrap" >> "$GITHUB_OUTPUT"
          fi

      - name: Terraform Apply
        working-directory: infrastructure/terraform
        run: |
          terraform apply -auto-approve -input=false \
            -var-file="environments/prod.tfvars" \
            -var="db_password=${{ secrets.TF_VAR_db_password }}" \
            -var="google_client_id=${{ secrets.TF_VAR_google_client_id }}" \
            -var="google_client_secret=${{ secrets.TF_VAR_google_client_secret }}" \
            -var="alert_email_address=${{ secrets.TF_VAR_alert_email_address }}" \
            -var="placeholder_image_uri=${{ steps.bootstrap.outputs.placeholder_uri }}"

      - name: Get Terraform Outputs
        id: output
        working-directory: infrastructure/terraform
        run: |
          echo "lambda_function_name=$(terraform output -raw lambda_function_name)" >> $GITHUB_OUTPUT
          echo "migrate_function_name=$(terraform output -raw migrate_function_name)" >> $GITHUB_OUTPUT
          echo "image_processor_function_name=$(terraform output -raw image_processor_function_name)" >> $GITHUB_OUTPUT
          echo "api_gateway_url=$(terraform output -raw api_gateway_url)" >> $GITHUB_OUTPUT
          echo "ecr_repository_url=$(terraform output -raw ecr_repository_url)" >> $GITHUB_OUTPUT
          echo "migrate_ecr_repository_url=$(terraform output -raw migrate_ecr_repository_url)" >> $GITHUB_OUTPUT
          echo "image_processor_ecr_repository_url=$(terraform output -raw image_processor_ecr_repository_url)" >> $GITHUB_OUTPUT

  deploy-lambdas:
    name: Deploy Lambdas
    runs-on: ubuntu-latest
    needs: [build, terraform]

    steps:
      - name: Checkout
        uses: actions/checkout@v6

      - name: Download API artifact
        uses: actions/download-artifact@v7
        with:
          name: api-dist
          path: apps/api/dist/

      - name: Download migrate artifact
        uses: actions/download-artifact@v7
        with:
          name: migrate-dist
          path: tools/migrate/dist/

      - name: Configure AWS Credentials
        uses: aws-actions/configure-aws-credentials@v6
        with:
          aws-access-key-id: ${{ secrets.AWS_ACCESS_KEY_ID }}
          aws-secret-access-key: ${{ secrets.AWS_SECRET_ACCESS_KEY }}
          aws-region: ${{ env.AWS_REGION }}

      - name: Login to Amazon ECR
        uses: aws-actions/amazon-ecr-login@v2

      # --- API Lambda ---

      - name: Build API Docker image
        env:
          ECR_REPOSITORY_URL: ${{ needs.terraform.outputs.ecr_repository_url }}
          IMAGE_TAG: ${{ github.sha }}
        run: |
          docker build -f apps/api/Dockerfile \
            -t $ECR_REPOSITORY_URL:$IMAGE_TAG \
            .

      # Paths validated here must match the Dockerfile layout (apps/api/Dockerfile).
      - name: Validate API container
        env:
          ECR_REPOSITORY_URL: ${{ needs.terraform.outputs.ecr_repository_url }}
          IMAGE_TAG: ${{ github.sha }}
        run: |
          echo "Checking API container has required files..."
          docker run --rm --entrypoint="" \
            $ECR_REPOSITORY_URL:$IMAGE_TAG \
            sh -c '
              ok=true
              for f in /var/task/index.js; do
                if test -f "$f"; then
                  echo "OK   $f"
                else
                  echo "MISSING $f" >&2; ok=false
                fi
              done
              # Verify Prisma WASM query compiler chunks were copied
              count=$(ls /var/task/query_compiler_fast_bg.postgresql*.js 2>/dev/null | wc -l)
              if [ "$count" -ge 1 ]; then
                echo "OK   Prisma WASM chunks ($count files)"
              else
                echo "MISSING Prisma WASM chunks (query_compiler_fast_bg.postgresql*.js)" >&2; ok=false
              fi
              $ok && echo "All required files present." || { echo "Validation failed" >&2; exit 1; }
            '

      - name: Push API Docker image
        env:
          ECR_REPOSITORY_URL: ${{ needs.terraform.outputs.ecr_repository_url }}
          IMAGE_TAG: ${{ github.sha }}
        run: |
          docker push $ECR_REPOSITORY_URL:$IMAGE_TAG

      - name: Deploy API Lambda
        env:
          ECR_REPOSITORY_URL: ${{ needs.terraform.outputs.ecr_repository_url }}
          IMAGE_TAG: ${{ github.sha }}
        run: |
          aws lambda update-function-code \
            --function-name ${{ needs.terraform.outputs.lambda_function_name }} \
            --image-uri $ECR_REPOSITORY_URL:$IMAGE_TAG

      # --- Migration Lambda ---

      # Build context must be monorepo root (.) because the Dockerfile COPYs
      # package.json, package-lock.json, and workspace manifests from the root.
      - name: Build migrate Docker image
        env:
          ECR_REPOSITORY_URL: ${{ needs.terraform.outputs.migrate_ecr_repository_url }}
          IMAGE_TAG: ${{ github.sha }}
        run: |
          docker build -f tools/migrate/Dockerfile \
            -t $ECR_REPOSITORY_URL:$IMAGE_TAG \
            .

      # Paths validated here must match the Dockerfile layout (tools/migrate/Dockerfile)
      # and the runtime constants in tools/migrate/src/index.ts (PRISMA_CLI path).
      - name: Validate migrate container
        env:
          ECR_REPOSITORY_URL: ${{ needs.terraform.outputs.migrate_ecr_repository_url }}
          IMAGE_TAG: ${{ github.sha }}
        run: |
          echo "Checking migrate container has required files..."
          docker run --rm --entrypoint="" \
            $ECR_REPOSITORY_URL:$IMAGE_TAG \
            sh -c '
              ok=true
              for f in \
                /var/task/index.js \
                /var/task/node_modules/prisma/build/index.js \
                /var/task/prisma/schema.prisma \
                /var/task/prisma.config.ts; do
                if test -f "$f"; then
                  echo "OK   $f"
                else
                  echo "MISSING $f" >&2; ok=false
                fi
              done
              if ! test -d /var/task/prisma/migrations; then
                echo "MISSING /var/task/prisma/migrations/" >&2; ok=false
              else
                echo "OK   /var/task/prisma/migrations/"
              fi
              $ok && echo "All required files present." || { echo "Validation failed" >&2; exit 1; }
            '

      - name: Push migrate Docker image
        env:
          ECR_REPOSITORY_URL: ${{ needs.terraform.outputs.migrate_ecr_repository_url }}
          IMAGE_TAG: ${{ github.sha }}
        run: |
          docker push $ECR_REPOSITORY_URL:$IMAGE_TAG

      - name: Deploy migrate Lambda
        env:
          ECR_REPOSITORY_URL: ${{ needs.terraform.outputs.migrate_ecr_repository_url }}
          IMAGE_TAG: ${{ github.sha }}
        run: |
          aws lambda update-function-code \
            --function-name ${{ needs.terraform.outputs.migrate_function_name }} \
            --image-uri $ECR_REPOSITORY_URL:$IMAGE_TAG

      # --- Image Processor Lambda ---

      - name: Download image-processor artifact
        uses: actions/download-artifact@v7
        with:
          name: image-processor-dist
          path: apps/image-processor/dist/

      - name: Build image-processor Docker image
        env:
          ECR_REPOSITORY_URL: ${{ needs.terraform.outputs.image_processor_ecr_repository_url }}
          IMAGE_TAG: ${{ github.sha }}
        run: |
          docker build -f apps/image-processor/Dockerfile \
            -t $ECR_REPOSITORY_URL:$IMAGE_TAG \
            .

      - name: Validate image-processor container
        env:
          ECR_REPOSITORY_URL: ${{ needs.terraform.outputs.image_processor_ecr_repository_url }}
          IMAGE_TAG: ${{ github.sha }}
        run: |
          echo "Checking image-processor container has required files..."
          docker run --rm --entrypoint="" \
            $ECR_REPOSITORY_URL:$IMAGE_TAG \
            sh -c '
              ok=true
              for f in /var/task/index.js; do
                if test -f "$f"; then
                  echo "OK   $f"
                else
                  echo "MISSING $f" >&2; ok=false
                fi
              done
              if test -d /var/task/node_modules/sharp; then
                echo "OK   Sharp native binaries"
              else
                echo "MISSING Sharp native binaries" >&2; ok=false
              fi
              $ok && echo "All required files present." || { echo "Validation failed" >&2; exit 1; }
            '

      - name: Push image-processor Docker image
        env:
          ECR_REPOSITORY_URL: ${{ needs.terraform.outputs.image_processor_ecr_repository_url }}
          IMAGE_TAG: ${{ github.sha }}
        run: |
          docker push $ECR_REPOSITORY_URL:$IMAGE_TAG

      - name: Deploy image-processor Lambda
        env:
          ECR_REPOSITORY_URL: ${{ needs.terraform.outputs.image_processor_ecr_repository_url }}
          IMAGE_TAG: ${{ github.sha }}
        run: |
          aws lambda update-function-code \
            --function-name ${{ needs.terraform.outputs.image_processor_function_name }} \
            --image-uri $ECR_REPOSITORY_URL:$IMAGE_TAG

      # --- Wait for all updates ---

      - name: Wait for Lambda updates
        run: |
          aws lambda wait function-updated \
            --function-name ${{ needs.terraform.outputs.lambda_function_name }}
          aws lambda wait function-updated \
            --function-name ${{ needs.terraform.outputs.migrate_function_name }}
          aws lambda wait function-updated \
            --function-name ${{ needs.terraform.outputs.image_processor_function_name }}

  migrate-database:
    name: Run Migrations
    runs-on: ubuntu-latest
    needs: [terraform, deploy-lambdas]

    steps:
      - name: Setup Node.js
        uses: actions/setup-node@v6
        with:
          node-version: ${{ env.NODE_VERSION }}

      - name: Configure AWS Credentials
        uses: aws-actions/configure-aws-credentials@v6
        with:
          aws-access-key-id: ${{ secrets.AWS_ACCESS_KEY_ID }}
          aws-secret-access-key: ${{ secrets.AWS_SECRET_ACCESS_KEY }}
          aws-region: ${{ env.AWS_REGION }}

      - name: Run migrations via Lambda
        run: |
          aws lambda invoke \
            --function-name ${{ needs.terraform.outputs.migrate_function_name }} \
            --payload '{"command":"migrate"}' \
            --cli-binary-format raw-in-base64-out \
            /tmp/migrate-response.json

          echo "Migration response:"
          cat /tmp/migrate-response.json

          node -e "
            const r = JSON.parse(require('fs').readFileSync('/tmp/migrate-response.json', 'utf8'));
            if (!r.success) { console.error('Migration failed:', r.error); process.exit(1); }
            console.log('Migrations completed successfully');
          "

  verify:
    name: Verify Deployment
    runs-on: ubuntu-latest
    needs: [terraform, deploy-lambdas, migrate-database]

    steps:
      - name: Health Check
        run: |
          API_URL="${{ needs.terraform.outputs.api_gateway_url }}"
          echo "Checking health at $API_URL/health"

          for i in {1..5}; do
            response=$(curl -s -o /dev/null -w "%{http_code}" "$API_URL/health")
            if [ "$response" == "200" ]; then
              echo "Health check passed!"
              exit 0
            fi
            echo "Attempt $i: Got $response, retrying..."
            sleep 5
          done

          echo "Health check failed after 5 attempts"
          exit 1

  notify-releases:
    name: Notify Releases
    runs-on: ubuntu-latest
    needs: [verify]
    if: success()
    continue-on-error: true
    timeout-minutes: 2

    steps:
      - name: Gather PR and commit data
        id: pr_data
        uses: actions/github-script@v7
        with:
          github-token: ${{ secrets.GITHUB_TOKEN }}
          script: |
            try {
              // Resolve the PR from the merge commit SHA
              const { data: prs } = await github.rest.repos.listPullRequestsAssociatedWithCommit({
                owner: context.repo.owner,
                repo: context.repo.repo,
                commit_sha: context.sha,
              });

              const mergedPr = prs.find(pr => pr.merged_at !== null);
              if (!mergedPr) {
                core.info('No merged PR found for this commit ‚Äî skipping releases notification');
                core.setOutput('skip', 'true');
                return;
              }

              core.setOutput('skip', 'false');
              core.setOutput('pr_number', mergedPr.number);
              core.setOutput('pr_title', mergedPr.title);
              core.setOutput('pr_url', mergedPr.html_url);
              core.setOutput('pr_author', mergedPr.user.login);
              core.setOutput('pr_body', mergedPr.body || '');
              core.setOutput('head_branch', mergedPr.head.ref);

              // Get all commits in the PR
              const { data: commits } = await github.rest.pulls.listCommits({
                owner: context.repo.owner,
                repo: context.repo.repo,
                pull_number: mergedPr.number,
                per_page: 100,
              });

              const commitMessages = commits
                .map(c => `- ${c.commit.message.split('\n')[0]}`)
                .join('\n');
              core.setOutput('commit_messages', commitMessages);
              core.setOutput('commit_count', commits.length.toString());

              // Get linked issues via GraphQL
              let linkedIssues = [];
              try {
                const graphqlResult = await github.graphql(`
                  query($owner: String!, $repo: String!, $number: Int!) {
                    repository(owner: $owner, name: $repo) {
                      pullRequest(number: $number) {
                        closingIssuesReferences(first: 20) {
                          nodes {
                            number
                            title
                            url
                          }
                        }
                      }
                    }
                  }
                `, {
                  owner: context.repo.owner,
                  repo: context.repo.repo,
                  number: mergedPr.number,
                });
                linkedIssues = graphqlResult.repository.pullRequest.closingIssuesReferences.nodes || [];
              } catch (e) {
                core.warning(`Failed to fetch linked issues via GraphQL: ${e.message}`);
              }

              // Also parse PR body for additional #N references
              const additionalRefs = [];
              if (mergedPr.body) {
                const linkedNumbers = new Set(linkedIssues.map(i => i.number));
                const matches = mergedPr.body.match(/#(\d+)/g) || [];
                for (const match of matches) {
                  const num = parseInt(match.slice(1), 10);
                  if (!linkedNumbers.has(num)) {
                    additionalRefs.push(num);
                  }
                }
              }

              core.setOutput('linked_issues', JSON.stringify(linkedIssues));
              core.setOutput('additional_refs', JSON.stringify(additionalRefs));

              // Get changed files
              const { data: files } = await github.rest.pulls.listFiles({
                owner: context.repo.owner,
                repo: context.repo.repo,
                pull_number: mergedPr.number,
                per_page: 100,
              });

              let totalAdditions = 0;
              let totalDeletions = 0;
              for (const f of files) {
                totalAdditions += f.additions;
                totalDeletions += f.deletions;
              }
              core.setOutput('files_count', files.length.toString());
              core.setOutput('diff_stats', `+${totalAdditions} / -${totalDeletions}`);

              // Determine affected workspace areas
              const areaMap = {
                'apps/web/': 'Frontend',
                'apps/api/': 'Backend',
                'packages/db/': 'Database',
                'packages/types/': 'Types',
                'packages/utils/': 'Utilities',
                'infrastructure/terraform/': 'Infrastructure',
                '.github/workflows/': 'CI/CD',
              };
              const areasSet = new Set();
              for (const f of files) {
                for (const [prefix, area] of Object.entries(areaMap)) {
                  if (f.filename.startsWith(prefix)) {
                    areasSet.add(area);
                  }
                }
              }
              core.setOutput('areas', Array.from(areasSet).join(', ') || 'Other');
            } catch (error) {
              core.warning(`Failed to gather PR data: ${error.message}`);
              core.setOutput('skip', 'true');
            }

      - name: Generate AI summary
        id: ai_summary
        if: steps.pr_data.outputs.skip != 'true'
        continue-on-error: true
        env:
          ANTHROPIC_API_KEY: ${{ secrets.ANTHROPIC_API_KEY }}
          PR_TITLE: ${{ steps.pr_data.outputs.pr_title }}
          HEAD_BRANCH: ${{ steps.pr_data.outputs.head_branch }}
          AREAS: ${{ steps.pr_data.outputs.areas }}
          COMMIT_MESSAGES: ${{ steps.pr_data.outputs.commit_messages }}
          PR_BODY: ${{ steps.pr_data.outputs.pr_body }}
        run: |
          # Build the prompt payload using jq for proper JSON escaping
          PROMPT=$(cat <<'PROMPT_EOF'
          Summarize this pull request merge for a Slack notification to a non-technical team. Write 1-5 sentences max per feature in plain English. Focus on what changed from a product or feature perspective ‚Äî what would a user or stakeholder notice? Make sure to highlight changes to buyer and artist experience. Do not mention file names, function names, or technical implementation details unless they ARE the feature (e.g., "Added CI/CD pipeline" is fine). Be concise and direct.

          CRITICAL formatting rules ‚Äî this text will be rendered in Slack mrkdwn, NOT standard Markdown:
          - Use *single asterisks* for bold (NOT **double asterisks**)
          - Use _underscores_ for italics (NOT *single asterisks*)
          - Use ~tildes~ for strikethrough
          - Use `backticks` for inline code
          - Do NOT use # headings ‚Äî Slack mrkdwn has no heading syntax. Use *_bold underline text_* on its own line instead
          - Standard Markdown bold (**text**) and headings (# text) will NOT render in Slack and will show raw characters
          PROMPT_EOF
          )

          USER_CONTENT=$(jq -n \
            --arg prompt "$PROMPT" \
            --arg pr_title "$PR_TITLE" \
            --arg branch "$HEAD_BRANCH" \
            --arg areas "$AREAS" \
            --arg commits "$COMMIT_MESSAGES" \
            --arg body "$PR_BODY" \
            '$prompt + "\n\nPR Title: " + $pr_title + "\nBranch: " + $branch + "\nAreas affected: " + $areas + "\n\nCommits:\n" + $commits + "\n\nPR Description:\n" + $body')

          PAYLOAD=$(jq -n \
            --arg content "$USER_CONTENT" \
            '{
              model: "claude-haiku-4-5-20251001",
              max_tokens: 200,
              messages: [{role: "user", content: $content}]
            }')

          RESPONSE=$(curl -s --max-time 30 \
            -H "Content-Type: application/json" \
            -H "x-api-key: $ANTHROPIC_API_KEY" \
            -H "anthropic-version: 2023-06-01" \
            -d "$PAYLOAD" \
            https://api.anthropic.com/v1/messages)

          SUMMARY=$(echo "$RESPONSE" | jq -r '.content[0].text // "Summary unavailable ‚Äî see PR for details."')

          if [ -z "$SUMMARY" ] || [ "$SUMMARY" = "null" ]; then
            SUMMARY="Summary unavailable ‚Äî see PR for details."
          fi

          # Use a delimiter for multiline output
          EOF_MARKER=$(dd if=/dev/urandom bs=15 count=1 2>/dev/null | base64)
          echo "summary<<$EOF_MARKER" >> "$GITHUB_OUTPUT"
          echo "$SUMMARY" >> "$GITHUB_OUTPUT"
          echo "$EOF_MARKER" >> "$GITHUB_OUTPUT"

      - name: Send to Slack releases channel
        if: steps.pr_data.outputs.skip != 'true'
        env:
          SLACK_WEBHOOK_URL: ${{ secrets.SLACK_RELEASES_WEBHOOK_URL }}
          AI_SUMMARY: ${{ steps.ai_summary.outputs.summary }}
          PR_NUMBER: ${{ steps.pr_data.outputs.pr_number }}
          PR_TITLE: ${{ steps.pr_data.outputs.pr_title }}
          PR_URL: ${{ steps.pr_data.outputs.pr_url }}
          PR_AUTHOR: ${{ steps.pr_data.outputs.pr_author }}
          COMMIT_COUNT: ${{ steps.pr_data.outputs.commit_count }}
          DIFF_STATS: ${{ steps.pr_data.outputs.diff_stats }}
          AREAS: ${{ steps.pr_data.outputs.areas }}
          FILES_COUNT: ${{ steps.pr_data.outputs.files_count }}
          LINKED_ISSUES: ${{ steps.pr_data.outputs.linked_issues }}
        run: |
          SUMMARY="$AI_SUMMARY"
          if [ -z "$SUMMARY" ]; then
            SUMMARY="Summary unavailable ‚Äî see PR for details."
          fi

          # Convert Markdown formatting to Slack mrkdwn (safety net)
          # **bold** ‚Üí *bold*
          SUMMARY=$(echo "$SUMMARY" | sed 's/\*\*\([^*]*\)\*\*/\*\1\*/g')
          # # Heading ‚Üí *_Heading_* (strip 1-3 leading #'s and wrap in bold+underline)
          SUMMARY=$(echo "$SUMMARY" | sed 's/^#\{1,3\} \+\(.*\)/\*_\1_\*/')

          # Build linked issues section if any exist
          ISSUES_BLOCK="[]"
          ISSUE_COUNT=$(echo "$LINKED_ISSUES" | jq 'length' 2>/dev/null || echo "0")
          if [ "$ISSUE_COUNT" -gt "0" ]; then
            ISSUES_TEXT=$(echo "$LINKED_ISSUES" | jq -r '.[] | "‚Ä¢ <\(.url)|#\(.number)> \(.title)"' | head -20)
            ISSUES_BLOCK=$(jq -n \
              --arg text "$ISSUES_TEXT" \
              '[{"type": "section", "text": {"type": "mrkdwn", "text": ("*Linked Issues*\n" + $text)}}]')
          fi

          # Build the Block Kit payload
          PAYLOAD=$(jq -n \
            --arg pr_title "$PR_TITLE" \
            --arg summary "$SUMMARY" \
            --arg pr_url "$PR_URL" \
            --arg pr_number "$PR_NUMBER" \
            --arg pr_author "$PR_AUTHOR" \
            --arg commit_count "$COMMIT_COUNT" \
            --arg diff_stats "$DIFF_STATS" \
            --arg areas "$AREAS" \
            --arg files_count "$FILES_COUNT" \
            --argjson issues_block "$ISSUES_BLOCK" \
            '{
              blocks: ([
                {
                  type: "header",
                  text: {
                    type: "plain_text",
                    text: ("‚úÖ Deployed to production: " + $pr_title),
                    emoji: true
                  }
                },
                {
                  type: "section",
                  text: {
                    type: "mrkdwn",
                    text: $summary
                  }
                },
                {
                  type: "divider"
                },
                {
                  type: "section",
                  fields: [
                    {type: "mrkdwn", text: ("*PR*\n<" + $pr_url + "|#" + $pr_number + ">")},
                    {type: "mrkdwn", text: ("*Author*\n" + $pr_author)},
                    {type: "mrkdwn", text: ("*Commits*\n" + $commit_count)},
                    {type: "mrkdwn", text: ("*Diff*\n" + $diff_stats)}
                  ]
                },
                {
                  type: "section",
                  text: {
                    type: "mrkdwn",
                    text: ("*Areas:* " + $areas)
                  }
                }
              ] + $issues_block + [
                {
                  type: "context",
                  elements: [
                    {type: "mrkdwn", text: ("üìÅ " + $files_count + " files changed")}
                  ]
                }
              ])
            }')

          curl -s --max-time 10 \
            -H "Content-Type: application/json" \
            -d "$PAYLOAD" \
            "$SLACK_WEBHOOK_URL" || true

  notify-actions-deploy:
    name: Notify Actions (Deploy)
    runs-on: ubuntu-latest
    needs: [build, terraform, deploy-lambdas, migrate-database, verify]
    if: always()
    continue-on-error: true
    timeout-minutes: 2

    steps:
      - name: Gather PR data
        id: pr_data
        uses: actions/github-script@v7
        with:
          github-token: ${{ secrets.GITHUB_TOKEN }}
          script: |
            try {
              const { data: prs } = await github.rest.repos.listPullRequestsAssociatedWithCommit({
                owner: context.repo.owner,
                repo: context.repo.repo,
                commit_sha: context.sha,
              });

              const mergedPr = prs.find(pr => pr.merged_at !== null);
              if (!mergedPr) {
                core.setOutput('has_pr', 'false');
                core.setOutput('commit_sha', context.sha.substring(0, 7));
                return;
              }

              core.setOutput('has_pr', 'true');
              core.setOutput('pr_number', mergedPr.number);
              core.setOutput('pr_title', mergedPr.title);
              core.setOutput('pr_url', mergedPr.html_url);
              core.setOutput('pr_author', mergedPr.user.login);

              const { data: commits } = await github.rest.pulls.listCommits({
                owner: context.repo.owner,
                repo: context.repo.repo,
                pull_number: mergedPr.number,
                per_page: 100,
              });
              core.setOutput('commit_count', commits.length.toString());

              const { data: files } = await github.rest.pulls.listFiles({
                owner: context.repo.owner,
                repo: context.repo.repo,
                pull_number: mergedPr.number,
                per_page: 100,
              });

              let totalAdditions = 0;
              let totalDeletions = 0;
              for (const f of files) {
                totalAdditions += f.additions;
                totalDeletions += f.deletions;
              }
              core.setOutput('files_count', files.length.toString());
              core.setOutput('diff_stats', `+${totalAdditions} / -${totalDeletions}`);

              const areaMap = {
                'apps/web/': 'Frontend',
                'apps/api/': 'Backend',
                'packages/db/': 'Database',
                'packages/types/': 'Types',
                'packages/utils/': 'Utilities',
                'infrastructure/terraform/': 'Infrastructure',
                '.github/workflows/': 'CI/CD',
              };
              const areasSet = new Set();
              for (const f of files) {
                for (const [prefix, area] of Object.entries(areaMap)) {
                  if (f.filename.startsWith(prefix)) {
                    areasSet.add(area);
                  }
                }
              }
              core.setOutput('areas', Array.from(areasSet).join(', ') || 'Other');
            } catch (error) {
              core.warning(`Failed to gather PR data: ${error.message}`);
              core.setOutput('has_pr', 'false');
              core.setOutput('commit_sha', context.sha.substring(0, 7));
            }

      - name: Determine deploy status
        id: status
        run: |
          if [ "${{ needs.verify.result }}" = "success" ]; then
            echo "result=success" >> "$GITHUB_OUTPUT"
            echo "emoji=‚úÖ" >> "$GITHUB_OUTPUT"
            echo "text=succeeded" >> "$GITHUB_OUTPUT"
          else
            echo "result=failure" >> "$GITHUB_OUTPUT"
            echo "emoji=‚ùå" >> "$GITHUB_OUTPUT"
            echo "text=failed" >> "$GITHUB_OUTPUT"
          fi

      - name: Get failure context
        id: failure
        if: steps.status.outputs.result == 'failure'
        uses: actions/github-script@v7
        with:
          github-token: ${{ secrets.GITHUB_TOKEN }}
          script: |
            try {
              const { data: jobs } = await github.rest.actions.listJobsForWorkflowRun({
                owner: context.repo.owner,
                repo: context.repo.repo,
                run_id: context.runId,
              });

              const failedJob = jobs.jobs.find(j => j.conclusion === 'failure');
              if (failedJob) {
                const failedStep = failedJob.steps?.find(s => s.conclusion === 'failure');
                core.setOutput('failed_step', failedStep ? failedStep.name : failedJob.name);
              } else {
                core.setOutput('failed_step', 'Unknown step');
              }
            } catch (error) {
              core.warning(`Failed to get failure context: ${error.message}`);
              core.setOutput('failed_step', 'Unknown step');
            }

      # Success with a PR is already covered by notify-releases ‚Äî skip actions channel
      - name: Send failure to Slack actions channel
        if: steps.status.outputs.result == 'failure' && steps.pr_data.outputs.has_pr == 'true'
        env:
          SLACK_WEBHOOK_URL: ${{ secrets.SLACK_ACTIONS_WEBHOOK_URL }}
          PR_TITLE: ${{ steps.pr_data.outputs.pr_title }}
          PR_URL: ${{ steps.pr_data.outputs.pr_url }}
          PR_NUMBER: ${{ steps.pr_data.outputs.pr_number }}
          PR_AUTHOR: ${{ steps.pr_data.outputs.pr_author }}
          FAILED_STEP: ${{ steps.failure.outputs.failed_step }}
          RUN_URL: ${{ github.server_url }}/${{ github.repository }}/actions/runs/${{ github.run_id }}
        run: |
          PAYLOAD=$(jq -n \
            --arg pr_title "$PR_TITLE" \
            --arg pr_url "$PR_URL" \
            --arg pr_number "$PR_NUMBER" \
            --arg pr_author "$PR_AUTHOR" \
            --arg failed_step "$FAILED_STEP" \
            --arg run_url "$RUN_URL" \
            '{
              blocks: [
                {
                  type: "header",
                  text: {type: "plain_text", text: ("‚ùå main deploy failed"), emoji: true}
                },
                {
                  type: "section",
                  text: {
                    type: "mrkdwn",
                    text: ("*PR:* <" + $pr_url + "|#" + $pr_number + "> " + $pr_title + "\n*Author:* " + $pr_author + "\n*Failed step:* " + $failed_step)
                  }
                },
                {
                  type: "actions",
                  elements: [
                    {
                      type: "button",
                      text: {type: "plain_text", text: "üîó View workflow run", emoji: true},
                      url: $run_url
                    }
                  ]
                }
              ]
            }')

          curl -s --max-time 10 \
            -H "Content-Type: application/json" \
            -d "$PAYLOAD" \
            "$SLACK_WEBHOOK_URL" || true

      - name: Send minimal notification (no PR)
        if: steps.pr_data.outputs.has_pr == 'false'
        env:
          SLACK_WEBHOOK_URL: ${{ secrets.SLACK_ACTIONS_WEBHOOK_URL }}
          COMMIT_SHA: ${{ steps.pr_data.outputs.commit_sha }}
          STATUS_EMOJI: ${{ steps.status.outputs.emoji }}
          STATUS_TEXT: ${{ steps.status.outputs.text }}
          RUN_URL: ${{ github.server_url }}/${{ github.repository }}/actions/runs/${{ github.run_id }}
        run: |
          PAYLOAD=$(jq -n \
            --arg emoji "$STATUS_EMOJI" \
            --arg status "$STATUS_TEXT" \
            --arg sha "$COMMIT_SHA" \
            --arg run_url "$RUN_URL" \
            '{
              blocks: [
                {
                  type: "section",
                  text: {
                    type: "mrkdwn",
                    text: ($emoji + " main deploy " + $status + " (direct push `" + $sha + "`) | <" + $run_url + "|View run>")
                  }
                }
              ]
            }')

          curl -s --max-time 10 \
            -H "Content-Type: application/json" \
            -d "$PAYLOAD" \
            "$SLACK_WEBHOOK_URL" || true
